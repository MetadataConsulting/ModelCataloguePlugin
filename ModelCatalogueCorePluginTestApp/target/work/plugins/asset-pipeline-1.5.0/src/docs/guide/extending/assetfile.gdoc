The @AssetFile@ definition is where our journey begins. This is the defining file for various file types. Without this definition, the asset-pipeline will treat an unknown file type as a standard passthrough resource. As an example, lets first look at the @CssAssetFile@ definition.

{code}
class CssAssetFile {
  static final String contentType = 'text/css'
  static extensions = ['css']
  static compiledExtension = 'css'
  static processors = [CssProcessor]

  File file
  def baseFile
  def encoding

  CssAssetFile(file,baseFile=null) {
    this.file = file
    this.baseFile = baseFile
  }

  def processedStream(precompiler=false) {

    def fileText
    if(baseFile?.encoding || encoding) {
      fileText = file?.getText(baseFile?.encoding ? baseFile.encoding : encoding)
    } else {
      fileText = file?.text
    }

    for(processor in processors) {
      def processInstance = processor.newInstance(precompiler)
      fileText = processInstance.process(fileText, this)
    }
    return fileText
    // Return File Stream
  }

  def directiveForLine(line) {
    line.find(/\*=(.*)/) { fullMatch, directive -> return directive }
  }
}
{code}

This file definition is pretty short but allows us to define some very useful information. First, we look at the static definitions at the top of the class. These static definitions are fairly easy to meta-override with Groovy and add additional processors or adjust with added plugins.

The @contentType@ property is used to match a file definition with an incoming file request. When the browser requests a @text/css@ content-type file , this file is matched and files matching this definition are scanned. The @extensions@ list tells asset-pipeline which file extensions to scan through and match. In this case it is just 'css', but in the case of LESS for example, we may be looking for extensions @less@, or @css.less@.

The @compiledExtension@ property tells asset-pipelines precompiler what the final file extension should be.

Finally, the @processors@ array determines the list of processors that need be run on the file contents before returning a result. This array is executed in order. In this case, we have the @CssProcessor@ (a processor for converting the relative image paths and replacing with their cache digested version).

h4. Directive Definition

An @assetFile@ can specify a REGEXP pattern for require directives. These directives are used to bundle assets together. Some file types don't utilize these require directives and simply returning a null value will cancel directive processing.

{code}
  def directiveForLine(line) {
    line.find(/\*=(.*)/) { fullMatch, directive -> return directive }
  }
{code}

The example above shows a match pattern for css files. This allows it to match require directives for the following example:

{code}
/*
*= require_self
*= require_file example_b
*= require_tree .
*/

body {
  margin-top:25px;
}
{code}

h4. Processing Data streams

Processors are used to precompile certain assets, and/or adjust the file path contents. The Processor class itself will get a more in depth explanation in the next section. For now the part we want to look at is the processedStream function.

{code}
def processedStream(precompiler=false) {

  def fileText = file?.text

  for(processor in processors) {
    def processInstance = processor.newInstance(precompiler)
    fileText = processInstance.process(fileText, this)
  }
  return fileText
  // Return File Stream
}
{code}

The example above iterates over all of the processor classes defined in our static @processors@ variable. This creates a new instance and informs the processor whether this is a developer mode request or being issued by the precompiler (useful for determining if file replacements need to be cache digested or not). The @processedStream@ method is required to be in every @AssetFile@ definition and some do vary. For example, the LESS and Coffee definitions take advantage of the @CacheManager@ to reduce development overhead by only recompiling changed files. An example of this is provided below:

{code}
def processedStream(precompiler=false) {
  def fileText = file?.text
  def md5 = AssetHelper.getByteDigest(fileText.bytes)
  if(!precompiler) {
    def cache = CacheManager.findCache(file.canonicalPath, md5)
    if(cache) {
      return cache
    }
  }
  for(processor in processors) {
    def processInstance = processor.newInstance(precompiler)
    fileText = processInstance.process(fileText, this)
  }

  if(!precompiler) {
    CacheManager.createCache(file.canonicalPath,md5,fileText)
  }

  return fileText
  // Return File Stream
}
{code}

In the future, we may further improve this extensibility by providing a default base class for these standard style stream methods.

h4. Adding the Asset definiton to the list of AssetFiles

Originally, asset-pipeline took advantage of the Artefact syntax to generate this class list. However, this became problematic as it added a great deal of overhead to precompilation during War creation. To solve this, an @asset.pipeline.AssetHelper.assetSpecs@ static array was used instead. This array is used by both development mode runtime and war creation so it has to be added in 2 places. If you are creating a plugin to facilitate your added functionality, you will want to use the @doWithDynamicMethods@ to add your asset file.

{code}
AssetHelper.assetSpecs << LessAssetFile
{code}

One other place we have to add this is in a @scripts/_Events.groovy@ file. An example below is pulled from the LESS asset-pipeline plugin.

{code}
eventAssetPrecompileStart = { assetConfig ->
  assetConfig.specs << 'asset.pipeline.less.LessAssetFile'
}
{code}

Notice on this one that the spec array is tied to @assetConfig@ and that instead of providing the class object we provide the classpath as a string. This is necessary to allow the precompiler to facilitate proper class loading across plugins as the full Grails stack may not be available during a precompile. This results in a significantly reduced memory overhead during precompiling as the alternative to using Artefacts. Granted, it does require an extra step here, but well worth the cost.
